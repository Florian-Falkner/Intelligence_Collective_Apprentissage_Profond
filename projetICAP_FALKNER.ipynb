{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet ICAP - FALKNER Florian\n",
    "#### Master SDSC - Université de Strasbourg\n",
    "\n",
    "Objectif: Détection d'événements anormaux dans les puits de pétrole\n",
    "\n",
    "#### 1. Data Analysis\n",
    "\n",
    "   Voir la partie 1 du projet. Ce que j'ai fait en plus c'est d'extraire la class y (celle à prédire) dans un dataframe à part et ensuite un dropout des colonnes que je n'ai pas besoin. Après le dropout, j'ai directement fait une normalisation des données par colonne en utilisant une fonction. Après la transformation, j'ai aussi fait un onehot pour y_train et y_test. Pour les 0 ça sera 1.0.0, les 8 -> 0.1.0 et les 108 -> 0.0.1\n",
    "\n",
    "#### 2. Data transformation\n",
    "\n",
    "   Pour la transformation des données, j'ai créé un petit bloc de codes pour transformer les données brutes pour avoir le même format que vos données transformées. Pour faire ceci, j'ai analysé vos fichiers Excels et fait quelques calculs pour retrouver le bon format. J'ai pu comprendre que le format se fait sur 25 timestep qui sont rangés dans un array. Donc la ligne 0 jusqu'à la ligne 24 seraient rangées dans un array et ensuite on fait +1 pour prendre les lignes 1 jusqu'à 25 et ainsi de suite. Chaque nouveau \"bloc\" de timestep est rangé dans un array différent. À la fin tous les arrays se retrouvent dans un grand array qui englobe tous les autres. Je convertis le dataset en numpy array, je prends la taille du dataset, je mets 25 pour le nombre de timestep, deux compteurs et deux listes. La listeX sera celle qui contiendra tous les autres array. \n",
    "   \n",
    "J'ai 2 boucles while, la 1ère vérifie s'il est possible de prendre les 25 prochains timestep. Si cela est bon, la 2ème boucle vérifie si le compteur (compteur de timestep) n'est pas égal au nombre de timestep qu'on veut (25). Si ça passe, je concatène le 1er timestep dans la liste1, ensuite 2ème timestep, 3ème, 4ème et ainsi de suite jusqu'à le compteur soit égal au nombre de timestep (25). Si c'est le cas, on incrémente le 2ème compteur, le 1er compteur est remis à 0 et on ajoute les 25 timestep (125 chiffres) de la list1 dans le grand array listX et on vide la liste1 pour qu'il soit utilisable pour sauvegarder les 25 prochains timestep. Il faut savoir que les 25 derniers timestep ne seront pas pris car sinon cela dépasse la limite avec les y, on aura donc 26974 lignes et non 26999.\n",
    "   \n",
    "   Pour le dataset y, j'extrais à partir de la longueur du timestep (25ème en partant de 0, ce qui représente la ligne 26) jusqu'à la longueur de la listeX + timestep. Ce qui nous donne aussi 26974 lignes. Donc pour la targetClasse on enlève les 25 premiers chiffres et dans celle de listX, on enlève les 25 derniers. Pour finir, je split les données pour l'entrainement et le test. Le code se trouve dans le bloc 3.\n",
    "   \n",
    "\n",
    "#### 3. Model set up\n",
    "\n",
    "   J'ai choisi d'utiliser 2 Conv1D avec une taille de noyau différente mais croissante. Je voulais pas en mettre trop pour ne pas avoir un modèle trop profond. Chaque couche de convolution est suivie par une couche de MaxPooling de taille 3. Maxpooling sert à réduire progressivement la taille spatiale de la représentation tout en conservant les informations les plus importantes pour les couches suivantes et réduit le nombre de paramètres. Ils ont une taille de 3. La taille du noyau est de 5 pour les Conv1D, pour qu'il ait la possibilité de se déplacer dans la matrice.\n",
    "   \n",
    "   Ensuite, j'ai mis une couche Flatten qui est obligatoire pour mettre les données en 1D sinon ça ne fonctionne pas.\n",
    "   Pour finir, j'ai 4 couches Dense (Fully-connected) dont une (la dernière) qui est à 3 car on peut avoir que 3 sorties, car les onehot font une taille de 3. Ces couches sont utiles pour la classification et je me suis dit que 4 Dense avec des filtres qui sont décroissants devraient suffire.  Pour toutes les couches sauf la dernière j'ai utilisé l'activation relu pour activer les différentes unités. Pour la dernière, j'ai utilisé sigmoid car on doit avoir un résultat entre 0 et 1 à cause des onehot.\n",
    "   \n",
    "   Le modèle n'est pas grand, il a ~120.000 paramètres. Je voulais un modèle qui soit cohérent et pas complexe. \n",
    "\n",
    "#### 4. Model training and evaluation\n",
    "\n",
    "   J'ai utilisé un EarlyStopping sur val_loss, le mode minimize et une patience de 4. Je trouve que c'est mieux d'utiliser un EarlyStopping sur les données du jeu de validation. J'utilise le mode min car je veux minimiser le validation loss. L'entrainement s'arrête lorsque la mesure de performance choisie cesse de s'améliorer. Je pense que patience = 4 est suffisant pour ce modèle qui a une epoch de 15.\n",
    "   \n",
    "   Ensuite, je compile le modèle en utilisant adam et le loss categorical_crossentropy. J'ai utlisé adam car en entrainent le modèle cela met moins de temps et est plus efficace. J'ai utilisé ce loss car il est fait pour les probabilités et il est fait pour calculer l'erreur s'il y a plus que 2 label, ce qui est le cas. \n",
    "   \n",
    "   L'entrainement du modèle se fait sur les x_train et sur les y_train onehot et ça sur 15 epochs. J'ai décidé de ne pas mettre plus car j'ai des bons résultats avec 15 donc je ne vois pas l'utilité de l'augmenter. Comme demandé, j'ai ajouté une validation_split de 0.2.\n",
    "  \n",
    "  En faisant un print du résumé du modèle, on peut voir le résumé du modèle mais aussi le nombre de paramètres. On peut voir le loss et la précision sur l'entrainement et sur la validation. En ayant mis verbose=1 à EarlyStopping, on peut voir à quelle epoch il s'est arrêté. J'ai aussi ajouté un plot qui affiche la précision sur les tests et training du modèle par rapport au epochs. On peut voir que le loss sur l'entrainement décroit toujours, pareil pour le loss sur les données de validation. Ceci nous indique qu'il n'y a pas d'overfit. On remarque aussi que la précision sur les deux côtés augmente et ne reste pas bloquée ou diminue.  \n",
    "  \n",
    "  Quand j'évalue le modèle sur x_test et y_test_ohe, la précision du modèle est très bonne. La précision est presque toujours entre 95% et 99%. Ceci nous indique que le modèle prédira très bien. Ensuite, j'enregistre les prédictions faite sur x_test dans la variable test. Je reconvertis les variables y_test_ohe et test en non onehot pour pourvoir les utiliser dans le random des 1000 instances et pour avoir un affichage correct dans la matrice de confusion.\n",
    "  \n",
    "  J'ai créé 1000 random instance comme demandé dans le projet. Je prends un nombre aléatoire entre 0 et la longueur de la variable test (prédictions faite sur x_test) et ensuite je prends le timestep correspondant au chiffre et j'enregistre le timstep x dans test_random et le y dans y_random.\n",
    "  \n",
    "  Le dernier bloc c'est pour la matrice de confusion. Comme le modèle apprend bien, les résultats sont très précis sauf parfois pour quelques labels mais c'est qu'une petite quantité. En lançant plusieurs fois l'évaluation j'ai pu remarquer qu'il prédit les 0 à 99-100% justes. C'est seulement pour les 8 et 108 où il ne prédit pas à 100% mais plutôt 95-99% justes. \n",
    "  \n",
    "  Je peux conclure que le modèle apprend et prédit bien sans être lourd et complexe, il atteint l'objectif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour la normalisation\n",
    "def scale_linear_bycolumn(rawpoints, high = 1.0, low = 0.0):\n",
    "    mins = np.min(rawpoints, axis = 0)\n",
    "    maxs = np.max(rawpoints, axis = 0)\n",
    "    rnge = maxs - mins\n",
    "    return high - (((high - low) * (maxs - rawpoints)) / rnge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données et dropout des colonnes\n",
    "df = pd.read_csv('donnees_brutes.csv')\n",
    "targetClass = df['class']\n",
    "df = df.drop(['timestamp', 'P-JUS-CKGL', 'T-JUS-CKGL', 'QGL', 'class'], axis = 1)\n",
    "\n",
    "# Normalisation des données\n",
    "df = scale_linear_bycolumn(df)\n",
    "\n",
    "\n",
    "# Transformation des données\n",
    "df = df.to_numpy()\n",
    "datasetLength = len(df)\n",
    "timestep = 25\n",
    "\n",
    "counter = 0\n",
    "i = 0\n",
    "\n",
    "list1 = []\n",
    "listX = []\n",
    "\n",
    "while(timestep < datasetLength):\n",
    "    while(counter != timestep):\n",
    "        list1.append(df[counter+i])\n",
    "        counter += 1\n",
    "    counter = 0\n",
    "    i += 1\n",
    "\n",
    "    listX.append(list1)\n",
    "    list1 = []\n",
    "    \n",
    "    datasetLength -= 1\n",
    "    \n",
    "targetClass = targetClass[timestep:len(listX)+timestep]\n",
    "targetClass = targetClass.to_numpy()\n",
    "listX = np.array(listX)\n",
    "\n",
    "# Training/Test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(listX, targetClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot de y_train et y_test\n",
    "onehot_encoder = OneHotEncoder(sparse = False)\n",
    "y_train_ohe = onehot_encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse = False)\n",
    "y_test_ohe = onehot_encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# 0 -> 1.0.0\n",
    "# 8 -> 0.1.0\n",
    "# 108 -> 0.0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "506/506 - 5s - loss: 0.1716 - accuracy: 0.9172 - val_loss: 0.1327 - val_accuracy: 0.9471\n",
      "Epoch 2/15\n",
      "506/506 - 2s - loss: 0.1109 - accuracy: 0.9519 - val_loss: 0.1124 - val_accuracy: 0.9545\n",
      "Epoch 3/15\n",
      "506/506 - 2s - loss: 0.0987 - accuracy: 0.9582 - val_loss: 0.0891 - val_accuracy: 0.9597\n",
      "Epoch 4/15\n",
      "506/506 - 2s - loss: 0.0862 - accuracy: 0.9665 - val_loss: 0.1166 - val_accuracy: 0.9605\n",
      "Epoch 5/15\n",
      "506/506 - 2s - loss: 0.0818 - accuracy: 0.9702 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
      "Epoch 6/15\n",
      "506/506 - 2s - loss: 0.0665 - accuracy: 0.9752 - val_loss: 0.0548 - val_accuracy: 0.9807\n",
      "Epoch 7/15\n",
      "506/506 - 2s - loss: 0.0901 - accuracy: 0.9681 - val_loss: 0.0922 - val_accuracy: 0.9654\n",
      "Epoch 8/15\n",
      "506/506 - 2s - loss: 0.0758 - accuracy: 0.9695 - val_loss: 0.1027 - val_accuracy: 0.9553\n",
      "Epoch 9/15\n",
      "506/506 - 2s - loss: 0.0784 - accuracy: 0.9663 - val_loss: 0.0494 - val_accuracy: 0.9834\n",
      "Epoch 10/15\n",
      "506/506 - 2s - loss: 0.0650 - accuracy: 0.9777 - val_loss: 0.1015 - val_accuracy: 0.9666\n",
      "Epoch 11/15\n",
      "506/506 - 2s - loss: 0.0657 - accuracy: 0.9748 - val_loss: 0.0595 - val_accuracy: 0.9768\n",
      "Epoch 12/15\n",
      "506/506 - 2s - loss: 0.0575 - accuracy: 0.9806 - val_loss: 0.0611 - val_accuracy: 0.9716\n",
      "Epoch 13/15\n",
      "506/506 - 2s - loss: 0.0718 - accuracy: 0.9732 - val_loss: 0.1215 - val_accuracy: 0.9570\n",
      "Epoch 00013: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 21, 64)            1664      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 3, 128)            41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 265)               34185     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               34048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 119,436\n",
      "Trainable params: 119,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Architecture du modèle\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 64, kernel_size = 5, activation = 'relu', input_shape = (25, 5)))\n",
    "model.add(MaxPooling1D(pool_size = 3))\n",
    "model.add(Conv1D(filters = 128, kernel_size = 5, activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size = 3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(265, activation = 'relu'))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "# Couche sortie\n",
    "model.add(Dense(3, activation = 'sigmoid'))\n",
    "\n",
    "# Early Stopping\n",
    "estopping = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 4, verbose = 1)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(x = x_train, y = y_train_ohe, epochs = 15, validation_split = 0.2, verbose = 2, callbacks=[estopping])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9555d2c7d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoAklEQVR4nO3deXQc9Znu8e+rbu2b5UXe5A0weMUYiy0EbDAwDoGQBYK5ZHMCDBngEpgEEjIM5CaTkzskk4FAYEwChBMSbgbCBMgCmCUOW8Bm9QLYeMHyJlmyJGtXt977R7VkWZbstqWWLNfzOadPV1VXV7/Vsuvp+lXVr8zdERGR8Eob6AJERGRgKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkUhYEZnafmZWb2YoeXjczu8PM1prZO2Z2fKpqERGRnqVyj+ABYME+Xv8EMDnxuAK4O4W1iIhID1IWBO6+FKjaxywXAA964FVgiJmNTlU9IiLSvegAfvZYYFOn8bLEtK1dZzSzKwj2GsjNzZ0zZcqUfilQRORwsXz58h3uPqK71wYyCKybad32d+Hui4HFAKWlpb5s2bJU1iUictgxs409vTaQZw2VAeM6jZcAWwaoFhGR0BrIIHgc+FLi7KGTgRp336tZSEREUitlTUNm9ltgHjDczMqAW4B0AHe/B/gTcC6wFmgAFqWqFhER6VnKgsDdL9nP6w5clarPFxGR5OjKYhHZUzwG1ZtA9yoJjYE8a0ik/7iDdXeimnSItcDbv4UX/wN2boCCEph8Fkw+BybNhcy8ga5QUkRBIIe+eCs01UJzTeK5Nnhuqtk93JwY32ta4jktHSZ8DI6YB0fMheJpCoZ2rY3wxoPw0u1QuxnGzIbSr8Gmv8O7j8DyByCSEXx/k8+Bo86G4ZND8f25OzWNrWyvbaZ8V1PHc3mX8drGGKMKsigpymbc0BxKirITjxzGFeVQkB3FDuHvywbbrSp1HcFhpPJDWPss1HzUZWPeZSPe2rD/ZaXnQlYBZBYEz1mFu4czC6B5F6xfClUfBvPnjgh+5R4xN3gumpDadT0UNe+C138Jr9wF9eUw/hQ4/Ztw5PzdG/lYC3z0Cqx5GtYugYr3gulDJgShMPkcmPhxyMhJ6iN31DWzckstKzbX8N62XQDkZUbIyYiSmxklLzNCbmaU3MR4bmakYzgvMZ6TESWSlsRGtaU+qLelHnKLg795dhGkpeHu7Gxo3b0xr22ifNfu5+3t47uaaYm17bXo/KwoxfmZjCzIojg/k/ysdLbVNlG2s5GyqgZ2Ncf2nD8zytg9QiJ4HleUQ8nQbAqy0pP6/nrDzJa7e2m3rykIpN+0NsHGF2HNkmDD0r5RjmbvuRHPTGzIOw/vNa3La5EorfE2qupb2FHXTGVdC5X1wfOOuhZaYm2MGZLFkRk7Oap+OcUVr5Kx6UWsbntQQ9HEYG9h0lyYdDrkDh+obyn1GnfC3xfDqz+Hpmo44gw4/Vsw8dT9v3fnRlj7TPA3XP/XIKSjWUEYTD4HJp8NQ4/A3dlW28SKzcFGf+WWGlZsrmVbbVPHokqKskmPpFHfHAseLfGkVyE7PdIRHPnpcFR0O5PZxKS2jYxr3cCYlnUUNW/BulyjGiNCNQWUeyE72vKpoJAdvvvRkFEEucVE8ovJHjKS4QW5FCc29u0b/eKCTHIy9t2YUtPQyqadDUEwdHneVNWw17oWZEWDvYehu0Oi83heZu8bbxQEMnA6NhzPBL/IOzYcpyU2HGfB0CO6fWtbm1Pb1MqOuhYq65qprA+ed3TayFfWtbAjMVzT2NrtcjIiaUQjRkOX/3zZ6Wmckl/BGZmrmRN/hyPr3yQzXg9Ay/DpRI86g7Qj5wW/lA+H9vG6Cnj1LnjtF9CyC445F077JpTMObjltTbBxpfwNU8Te/9p0qvXAbA1WsLz8Vn8uXkmr7VNodUyOHJEHjPGFjJ9TAHTxxQybUwBhdl7/gpua3MaWuM0NMeoa45R3xxPPMeob4lR3xTDajaRXf0BBbs+oKjuQ4obP6S4+SPSCf72cdL4iNF84CWsjI3jfS+hllzGZdQxMbOesRm7GJlWxzCrZkhbNbmtVWQ1V5LW1tLNChrkDA32JHJHQF5xsGeRlxjvGC4OXotmJvW1uTvVDa1BKOxs6BQUQUiU7WyksXXPf6tDctIpKcpm4Qnj+cLJB7f3qiCQ/tO5KWHNM7DjfQB8yASaJ51FTckZlA87gZrWKLVNrdQ0tlJVH2zQq+qDjX37hr+qvoVY297/Ps2gKCeDYbkZDMvLYFheJsNzg+dheRkMy81keN7u8fzEr6naxhhl1Q1s3tnI5urG3c+J4er6Rmbaek5NW8GpaSuYk/YBmRYjRoSPsqexbfjJNIz9OJkTT2TMsALGDskmKz2Ssq8y3ua0xNpoibfRmni0xNqIRtLISzSVJNVEUrsFXrojaOuPNcH0z8Bp/wyjZhxUTet31HX80l+xpYaVW2rZ1RRjgm3jzMjbnJu1guPi75LuLcSj2fikuUSPPjsI/iHjk/ug+kooX7X7sX0VlK8OAqxdQQkUT4WR04JjPsXTYPjRkJ4FBMHS2Bonkmb7/ju5B81k9RVQVx40k9VXBMFZX56YtiMxXLFnDe0sAmOOC/aMJp4G40+GzPzkv9g9ynGq6ls6BUWwN7GpqpEFM0ZxyYlJfoddS1QQSG+1xtuobWyltimWeG6ltjFGbVMr8Z1ljNi+lHGVL3HErtfJamuklSjvRGawlON4umUWq1uL6b57qUBuRqSbDXkwPCwvg+GdXivKSSca6fsznxtb4nsEw/bKKjK3vs7oqteY0vAGx7R9SJo59Z7Ja21TeLFtBquyZtM45BjGDM1ldGE2lviuWuLBRry100a8uWPcOzbqHRv5mAfDnaZ1k4F7ycmIBKGQFSU/K538REDkZUUpoZwzdjzEjPInMdooKzmfLTO/TqT46I4gyc8K2t/Tu/k+W2JtrCnfxcrNtR0b/FVbajt+rWZE05g6uoAZYwqYMbaQGWMKOXpUHpnRCLQ0wIYXEz8InobqRDc3I6YEzUeTz4FxJ0Nba9CO376hL18ZPLc32UHQrl88PdjoF0+FkdOD5WQP6f0f/WC0NnYJh/Jg/Ta+DGXLgnXqw2DoKwoC2ad4m7OlupENlfVsqGxg4456NlTWs6mqkerGFmobY3vsqkaJcbyt4YzIW8xLe5upaR8BsIXhvBYt5Z3sE1ifN4fMnAIKsqMUZKVTmJ1OQXZ6x3hBdjoFWenkZ0UpyskgOyN1v6z7SqyuiurVzxFf+zw5m18iv249ALVphSxPm8HzLdNYxRF8lDaOtmg2mdE00iNGeiSN9EgaGdE0MiJppEe7mZaYb/f47tfTI5Z4Dh7xtjZ2NQXNJ7uaYtS1DzfHqGtqpahhA59r+B3ntC0l7mn8d3wu98TPp8yLe1y3rPQ08jKDv0d+VpR4m7Nmex0t8eBAaW5GpKNJZ8bYQmaMLeDIEXndBshe3KFy7e5Q2PBSsLGMZkGsmY6+JqPZUDxl96/79o1+3sjBc4ZSSwOUvRaE4IYXD6lgUBAIsXgbW6qbEhv7ejbsaGBjZT3rK+vZVNVAa3z3v4PMaBoTh+UybmgOQ3ODDfaoSA1T6v7OxJ0vM7LiZdJbd+FpUVrGnASTzyZjyj9gxVMHz3/YvlCzOTjuse6F4MDprkRXWZYGRZP2bLIonhYcC4mk8Iztbe/C334CK/8n2MiWfpW2k6+iMXtkIjRaOwKkrqk9OBLj7aGSCJO4w9RR+UwfW8iMMQVMHJZLWjLNUMlorgu+t/VLg1/77d9T0URIO/R/EByQQygYFAQhEYu3sbm6kfU76tlY2cCGyno2VuxiU2UdW6rraIvHidJGGm3kphsTijKZUJTJuKIMxg/JpKQwk7FDMhieHSGNtuBUznUvBL/itr4dfEj+aDgqcZHREfOCs3ck+NVbtQ62rwiaNrYnmjiqPgRPnH4YyYQRR+8ZDiOnQcHY3gVo2TJY+mP44M+QkQ8nXQEn/9PhfebTYDWAwaAgGExiLcGBqvpEG2T7wavEgavYrnLitdvxplri8Rgej9HWFoe2OOZxIrQRSWzsI7SRZr38+1oajDtpd7vuyBnh+tXfW62NsOODRBt4+2N1cOFWu8zCPdu/i6cGIZEztOflusPGl2DpbUFYZxcFG/8TLw+GZXDox2BQEAy0loY9NuZ7n5FQgddX4HXlpDVVd7uIRjLZ4YVUeAE7vJBd5BDzCBaJkJuVSW5WJnnZGeTnZJGfk0VhTiY5mRlYJD34R5WWlniOQFq0y7RoML3j9cRwNAvGnaANSyo07oTy93YfHN2+Khhuqtk9T96oLs1LU2HEMbDxFfjbj4Ozs3KL4WPXQOlXD49TXMOupR42dQqGzcv3DIYTLofj9tmfZ4/2FQTqYqI33KGhCqo3QPVHwTnz1R8FZzx0nIa2A1rqun17Q1oe1VZIuReyNVZEedsEdnghlRSywwuopBDyikkvGEnRkCJGFWYxqiCLUYVZjB+SzcRhuQzPyzikL12XHmQXwYRTgkc79+A4Q+fTJctXwuu/CE777KygBM79Mcz+AqRn92/tkjoZuXDkGcED9g6G5tqUfKz2CPansTrYuFdv3HNj3z7eZSPfnF5AdWQ4O62Q7W0FbGnNZ1NLXscv+fZHbXQIwwvzOzbsowqzGN0xnM2ogiyG52Wk5DRJGWTa4lC1fnez0pBxMONCiGYMdGUyiGiPYF+a67rZ0G/cPd55Vx2Cg3FFE4IzHCbNDS6QKZrAW7sKuPVvu3ir3MnPjHZs3EcVZDG6MIvZhdmMKsxkVEE2owuzGJKTrl/ykpy0CAw/KnhM+9RAVyOHofAEwc4NQadZXX/VN1TuOV80u2PjzriTdw8PGR90tJVdtMfB0q01jfzbH1fz5DtbGTc0m198aTrzpxZrIy8ig0Z4gmDr2/DHfw660y0cF2zcRx8bbNyHjA9+4Q8ZH/QhksRGvCXWxi9fXM/PnltDvM257qyj+ce5R6S0ywERkVQITxAcOR+uXx2ciZHWu3b3pR9UcOvjK1m3o55zpo3k5vOmMW5oct3wiogcasITBJl5vT69blNVAz/44yqeWrmdScNzeWDRCcw7pufL9kVEBoPwBEEvNLXGWbx0HXc9v5Y0M25YcAxf+/ikoHMtEZFBTkGwH8+u3s73nljFR1UNfPLY0Xz33KmMGaLztkXk8KEg6MHGynq+98QqnnuvnKOK83jospM49Sj13SIihx8FQReNLXF+/sJa/uuv60iPGN89dypfOXVict3tiogMQgqCBHfnqZXb+P6Tq9lc3chnZo/lO5+YQnFB1kCXJiKSUgoC4MOKOm59fCV/W7ODKaPy+d0/nsKJk/bR86OIyGEk1EFQ1xzjZ8+t4b4X15OVHuHW86fxhZMnqH8fEQmVUAaBu/PEO1v5tz+uYnttM58vLeGGBVMYnpc50KWJiPS70AXB+9t2ccvjK3h1XRUzxhZw9xfmcPx49bcvIuEVmiCobWrlP59Zw69e2UB+VpR/+8wMFp4wnkhf3YdVRGSQCk0QLFm1nftfXs8lJ47nW+ccQ1Gu+nIXEYEQBcGnjxvL9DGFHDOqb28ILSIy2IXm9Ji0NFMIiIh0IzRBICIi3VMQiIiEXEqDwMwWmNn7ZrbWzL7dzetFZvaYmb1jZq+Z2YxU1iMiIntLWRCYWQS4C/gEMA24xMymdZntJuAtdz8W+BJwe6rqERGR7qVyj+BEYK27r3P3FuBh4IIu80wDngVw9/eAiWY2MoU1iYhIF6kMgrHApk7jZYlpnb0NfBbAzE4EJgAlXRdkZleY2TIzW1ZRUZGickVEwimVQdDdJbveZfxHQJGZvQVcA7wJxPZ6k/tidy9199IRI0b0eaEiImGWygvKyoBxncZLgC2dZ3D3WmARgJkZsD7xEBGRfpLKPYLXgclmNsnMMoCFwOOdZzCzIYnXAC4DlibCQURE+knK9gjcPWZmVwNPARHgPndfaWZXJl6/B5gKPGhmcWAV8LVU1SMiIt1LaV9D7v4n4E9dpt3TafgVYHIqaxARkX3TlcUiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQm5lAaBmS0ws/fNbK2Zfbub1wvN7Akze9vMVprZolTWIyIie0tZEJhZBLgL+AQwDbjEzKZ1me0qYJW7zwLmAT8xs4xU1SQiIntL5R7BicBad1/n7i3Aw8AFXeZxIN/MDMgDqoBYCmsSEZEuUhkEY4FNncbLEtM6uxOYCmwB3gWudfe2rgsysyvMbJmZLauoqEhVvSIioZTKILBupnmX8X8A3gLGAMcBd5pZwV5vcl/s7qXuXjpixIi+rlNEJNT2GwRmdp6ZHUxglAHjOo2XEPzy72wR8HsPrAXWA1MO4rNEROQgJbOBXwisMbN/N7OpB7Ds14HJZjYpcQB4IfB4l3k+AuYDmNlI4Bhg3QF8hoiI9FJ0fzO4+xcSzTWXAPebmQP3A7919137eF/MzK4GngIiwH3uvtLMrky8fg/wfeABM3uXoCnpRnff0eu1EhGRpJl712b7HmY0Gw58AfgGsBo4CrjD3X+Wsuq6UVpa6suWLevPjxQRGfTMbLm7l3b3WjLHCM43s8eA54B04ER3/wQwC/hmn1YqIiL9br9NQ8BFwE/dfWnnie7eYGZfTU1ZIiLSX5IJgluAre0jZpYNjHT3De7+bMoqExGRfpHMWUP/DXS+yCuemCYiIoeBZIIgmugiAoDEsPoDEhE5TCQTBBVm9qn2ETO7ANApniIih4lkjhFcCTxkZncSnOu/CfhSSqsSEZF+k8wFZR8CJ5tZHsF1Bz1eRCYiIoNPMnsEmNkngelAVtBjNLj7/0lhXSIi0k+SuaDsHuBi4BqCpqGLgAkprktERPpJMgeLP+buXwJ2uvv3gFPYs1dREREZxJIJgqbEc4OZjQFagUmpK0lERPpTMscInjCzIcBtwBsEN5e5N5VFiYhI/9lnECRuSPOsu1cDj5rZk0CWu9f0R3EiIpJ6+2waStw/+CedxpsVAiIih5dkjhE8bWafs/bzRkVE5LCSzDGC64FcIGZmTQSnkLq773WTeRERGXySubI4vz8KERGRgbHfIDCz07ub3vVGNSIiMjgl0zT0rU7DWcCJwHLgzJRUJCIi/SqZpqHzO4+b2Tjg31NWkYiI9KtkzhrqqgyY0deFiIjIwEjmGMHPCK4mhiA4jgPeTmFNIiLSj5I5RrCs03AM+K27v5SiekREpJ8lEwSPAE3uHgcws4iZ5bh7Q2pLExGR/pDMMYJngexO49nAktSUIyIi/S2ZIMhy97r2kcRwTupKEhGR/pRMENSb2fHtI2Y2B2hMXUkiItKfkjlG8A3gv81sS2J8NMGtK0VE5DCQzAVlr5vZFOAYgg7n3nP31pRXJiIi/SKZm9dfBeS6+wp3fxfIM7N/Sn1pIiLSH5I5RnB54g5lALj7TuDylFUkIiL9KpkgSOt8UxoziwAZqStJRET6UzIHi58Cfmdm9xB0NXEl8OeUViUiIv0mmSC4EbgC+DrBweI3Cc4cEhGRw8B+m4YSN7B/FVgHlALzgdXJLNzMFpjZ+2a21sy+3c3r3zKztxKPFWYWN7OhB7gOIiLSCz3uEZjZ0cBC4BKgEvh/AO5+RjILThxLuAs4m6Dr6tfN7HF3X9U+j7vfBtyWmP984Dp3rzq4VRERkYOxrz2C9wh+/Z/v7h93958B8QNY9onAWndf5+4twMPABfuY/xLgtwewfBER6QP7CoLPAduA583sXjObT3CMIFljgU2dxssS0/ZiZjnAAuDRHl6/wsyWmdmyioqKAyhBRET2p8cgcPfH3P1iYArwAnAdMNLM7jazc5JYdneh4d1MAzgfeKmnZiF3X+zupe5eOmLEiCQ+WkREkpXMweJ6d3/I3c8DSoC3gL0O/HajDBjXabwE2NLDvAtRs5CIyIA4oHsWu3uVu/+Xu5+ZxOyvA5PNbJKZZRBs7B/vOpOZFQJzgT8cSC0iItI3krmO4KC4e8zMria4IC0C3OfuK83sysTr9yRm/QzwtLvXp6oWERHpmbn31Gx/aCotLfVly5btf0YREelgZsvdvbS71w6oaUhERA4/CgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQUxCIiIScgkBEJOQUBCIiIacgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiIiEnIJARCTkFAQiIiGnIBARCTkFgYhIyCkIRERCTkEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICIScgoCEZGQS2kQmNkCM3vfzNaa2bd7mGeemb1lZivN7K+prEdERPYWTdWCzSwC3AWcDZQBr5vZ4+6+qtM8Q4CfAwvc/SMzK05VPSIi0r1U7hGcCKx193Xu3gI8DFzQZZ7/Bfze3T8CcPfyFNYjIiLdSGUQjAU2dRovS0zr7GigyMxeMLPlZval7hZkZleY2TIzW1ZRUZGickVEwimVQWDdTPMu41FgDvBJ4B+Am83s6L3e5L7Y3UvdvXTEiBF9X6mISIil7BgBwR7AuE7jJcCWbubZ4e71QL2ZLQVmAR+ksC4REekklXsErwOTzWySmWUAC4HHu8zzB+A0M4uaWQ5wErA6hTWJiEgXKdsjcPeYmV0NPAVEgPvcfaWZXZl4/R53X21mfwHeAdqAX7j7ilTVJCIiezP3rs32h7bS0lJftmzZQJchIgmtra2UlZXR1NQ00KUIkJWVRUlJCenp6XtMN7Pl7l7a3XtSeYxAREKgrKyM/Px8Jk6ciFl354hIf3F3KisrKSsrY9KkSUm/T11MiEivNDU1MWzYMIXAIcDMGDZs2AHvnSkIRKTXFAKHjoP5WygIRERCTkEgIhJyCgIRkSTFYrGBLiEldNaQiPSZ7z2xklVbavt0mdPGFHDL+dP3O9+nP/1pNm3aRFNTE9deey1XXHEFf/nLX7jpppuIx+MMHz6cZ599lrq6Oq655hqWLVuGmXHLLbfwuc99jry8POrq6gB45JFHePLJJ3nggQf4yle+wtChQ3nzzTc5/vjjufjii/nGN75BY2Mj2dnZ3H///RxzzDHE43FuvPFGnnrqKcyMyy+/nGnTpnHnnXfy2GOPAfDMM89w99138/vf/75Pv6PeUhCIyGHhvvvuY+jQoTQ2NnLCCSdwwQUXcPnll7N06VImTZpEVVUVAN///vcpLCzk3XffBWDnzp37XfYHH3zAkiVLiEQi1NbWsnTpUqLRKEuWLOGmm27i0UcfZfHixaxfv54333yTaDRKVVUVRUVFXHXVVVRUVDBixAjuv/9+Fi1alNLv4WAoCESkzyTzyz1V7rjjjo5f3ps2bWLx4sWcfvrpHefTDx06FIAlS5bw8MMPd7yvqKhov8u+6KKLiEQiANTU1PDlL3+ZNWvWYGa0trZ2LPfKK68kGo3u8Xlf/OIX+fWvf82iRYt45ZVXePDBB/tojfuOgkBEBr0XXniBJUuW8Morr5CTk8O8efOYNWsW77///l7zunu3p1h2ntb1PPzc3NyO4ZtvvpkzzjiDxx57jA0bNjBv3rx9LnfRokWcf/75ZGVlcdFFF3UExaFEB4tFZNCrqamhqKiInJwc3nvvPV599VWam5v561//yvr16wE6mobOOecc7rzzzo73tjcNjRw5ktWrV9PW1taxZ9HTZ40dG9xa5YEHHuiYfs4553DPPfd0HFBu/7wxY8YwZswYfvCDH/CVr3ylz9a5LykIRGTQW7BgAbFYjGOPPZabb76Zk08+mREjRrB48WI++9nPMmvWLC6++GIA/uVf/oWdO3cyY8YMZs2axfPPPw/Aj370I8477zzOPPNMRo8e3eNn3XDDDXznO9/h1FNPJR6Pd0y/7LLLGD9+PMceeyyzZs3iN7/5Tcdrl156KePGjWPatGkp+gZ6R53OiUivrF69mqlTpw50GYe0q6++mtmzZ/O1r32tXz6vu7+JOp0TERkgc+bMITc3l5/85CcDXUqPFAQiIim0fPnygS5hv3SMQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQk5BICKhkpeXN9AlHHJ0+qiI9J0/fxu2vdu3yxw1Ez7xo75d5iEgFosdMv0OaY9ARAa1G2+8kZ///Ocd47feeivf+973mD9/PscffzwzZ87kD3/4Q1LLqqur6/F9Dz74YEf3EV/84hcB2L59O5/5zGeYNWsWs2bN4uWXX2bDhg3MmDGj430//vGPufXWWwGYN28eN910E3PnzuX222/niSee4KSTTmL27NmcddZZbN++vaOORYsWMXPmTI499lgeffRRfvnLX3Ldddd1LPfee+/l+uuvP+jvbQ/uPqgec+bMcRE5dKxatWpAP/+NN97w008/vWN86tSpvnHjRq+pqXF394qKCj/yyCO9ra3N3d1zc3N7XFZra2u371uxYoUfffTRXlFR4e7ulZWV7u7++c9/3n/605+6u3ssFvPq6mpfv369T58+vWOZt912m99yyy3u7j537lz/+te/3vFaVVVVR1333nuvX3/99e7ufsMNN/i11167x3x1dXV+xBFHeEtLi7u7n3LKKf7OO+90ux7d/U2AZd7DdvXQ2C8RETlIs2fPpry8nC1btlBRUUFRURGjR4/muuuuY+nSpaSlpbF582a2b9/OqFGj9rksd+emm27a633PPfccF154IcOHDwd232vgueee67i/QCQSobCwcL83umnv/A6grKyMiy++mK1bt9LS0tJx74Se7plw5pln8uSTTzJ16lRaW1uZOXPmAX5b3VMQiMigd+GFF/LII4+wbds2Fi5cyEMPPURFRQXLly8nPT2diRMn7nWPge709D7v4V4D3YlGo7S1tXWM7+veBtdccw3XX389n/rUp3jhhRc6mpB6+rzLLruMH/7wh0yZMqVP73SmYwQiMugtXLiQhx9+mEceeYQLL7yQmpoaiouLSU9P5/nnn2fjxo1JLaen982fP5/f/e53VFZWArvvNTB//nzuvvtuAOLxOLW1tYwcOZLy8nIqKytpbm7mySef3Ofntd/b4Fe/+lXH9J7umXDSSSexadMmfvOb33DJJZck+/Xsl4JARAa96dOns2vXLsaOHcvo0aO59NJLWbZsGaWlpTz00ENMmTIlqeX09L7p06fz3e9+l7lz5zJr1qyOg7S33347zz//PDNnzmTOnDmsXLmS9PR0/vVf/5WTTjqJ8847b5+ffeutt3LRRRdx2mmndTQ7Qc/3TAD4/Oc/z6mnnprULTaTpfsRiEiv6H4E/eu8887juuuuY/78+T3Oc6D3I9AegYjIIFBdXc3RRx9Ndnb2PkPgYOhgsYiEzrvvvttxLUC7zMxM/v73vw9QRfs3ZMgQPvjgg5QsW0EgIr12IGfVHApmzpzJW2+9NdBlpMTBNPeraUhEeiUrK4vKysqD2gBJ33J3KisrycrKOqD3aY9ARHqlpKSEsrIyKioqBroUIQjmkpKSA3qPgkBEeiU9Pb3jilgZnFLaNGRmC8zsfTNba2bf7ub1eWZWY2ZvJR7/msp6RERkbynbIzCzCHAXcDZQBrxuZo+7+6ous/7N3c9LVR0iIrJvqdwjOBFY6+7r3L0FeBi4IIWfJyIiByGVxwjGAps6jZcBJ3Uz3ylm9jawBfimu6/sOoOZXQFckRitM7P3D7Km4cCOg3zvoUbrcmg6XNblcFkP0Lq0m9DTC6kMgu5OKu56ftkbwAR3rzOzc4H/ASbv9Sb3xcDiXhdktqynS6wHG63LoelwWZfDZT1A65KMVDYNlQHjOo2XEPzq7+Dute5elxj+E5BuZsMREZF+k8ogeB2YbGaTzCwDWAg83nkGMxtlicsRzezERD2VKaxJRES6SFnTkLvHzOxq4CkgAtzn7ivN7MrE6/cAFwJfN7MY0Ags9NRentjr5qVDiNbl0HS4rMvhsh6gddmvQdcNtYiI9C31NSQiEnIKAhGRkAtNEOyvu4vBwszGmdnzZrbazFaa2bUDXVNvmFnEzN40s55v7DoImNkQM3vEzN5L/G1OGeiaDpaZXZf4t7XCzH5rZgfWleUAMrP7zKzczFZ0mjbUzJ4xszWJ5767x2MK9bAutyX+jb1jZo+Z2ZC++KxQBEGn7i4+AUwDLjGzaQNb1UGLAf/s7lOBk4GrBvG6AFwLrB7oIvrA7cBf3H0KMItBuk5mNhb430Cpu88gONFj4cBWdUAeABZ0mfZt4Fl3nww8mxgfDB5g73V5Bpjh7scCHwDf6YsPCkUQcBh1d+HuW939jcTwLoINztiBrergmFkJ8EngFwNdS2+YWQFwOvBLAHdvcffqAS2qd6JAtplFgRy6XP9zKHP3pUBVl8kXAL9KDP8K+HR/1nSwulsXd3/a3WOJ0VcJrs/qtbAEQXfdXQzKjWdnZjYRmA0cuvfX27f/BG4A2ga4jt46AqgA7k80c/3CzHIHuqiD4e6bgR8DHwFbgRp3f3pgq+q1ke6+FYIfUkDxANfTV74K/LkvFhSWIEimu4tBxczygEeBb7h77UDXc6DM7Dyg3N2XD3QtfSAKHA/c7e6zgXoGT/PDHhLt5xcAk4AxQK6ZfWFgq5KuzOy7BM3ED/XF8sISBPvt7mIwMbN0ghB4yN1/P9D1HKRTgU+Z2QaCprozzezXA1vSQSsDyty9fc/sEYJgGIzOAta7e4W7twK/Bz42wDX11nYzGw2QeC4f4Hp6xcy+DJwHXNpXF+CGJQj2293FYJHokuOXwGp3/4+Brudguft33L3E3ScS/D2ec/dB+cvT3bcBm8zsmMSk+UDX+24MFh8BJ5tZTuLf2nwG6YHvTh4HvpwY/jLwhwGspVfMbAFwI/Apd2/oq+WGIggSB1fau7tYDfyuu+6uB4lTgS8S/IJuv7PbuQNdlHAN8JCZvQMcB/xwYMs5OIm9mkcIegZ+l2AbMWi6aDCz3wKvAMeYWZmZfQ34EXC2ma0huFHWjwayxmT1sC53AvnAM4n/+/f0yWepiwkRkXALxR6BiIj0TEEgIhJyCgIRkZBTEIiIhJyCQEQk5BQEIl2YWbzTqblv9WVvtWY2sXNvkiKHgpTdqlJkEGt09+MGugiR/qI9ApEkmdkGM/u/ZvZa4nFUYvoEM3s20Uf8s2Y2PjF9ZKLP+LcTj/auGiJmdm+iz/+nzSx7wFZKBAWBSHeyuzQNXdzptVp3P5HgCs//TEy7E3gw0Uf8Q8Adiel3AH9191kEfQ+1X80+GbjL3acD1cDnUro2IvuhK4tFujCzOnfP62b6BuBMd1+X6Phvm7sPM7MdwGh3b01M3+ruw82sAihx9+ZOy5gIPJO4SQpmdiOQ7u4/6IdVE+mW9ghEDoz3MNzTPN1p7jQcR8fqZIApCEQOzMWdnl9JDL/M7ts5Xgq8mBh+Fvg6dNybuaC/ihQ5EPolIrK3bDN7q9P4X9y9/RTSTDP7O8GPqEsS0/43cJ+ZfYvgTmWLEtOvBRYneo2ME4TC1lQXL3KgdIxAJEmJYwSl7r5joGsR6UtqGhIRCTntEYiIhJz2CEREQk5BICIScgoCEZGQUxCIiIScgkBEJOT+P+5jL8w/2hucAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Training/Test\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13026398420333862, 0.9532918334007263]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation du modèle\n",
    "model.evaluate(x = x_test, y = y_test_ohe, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predict\n",
    "test = model.predict(x_test)\n",
    "\n",
    "# Inverser OneHot\n",
    "test = onehot_encoder.inverse_transform(test).ravel()\n",
    "y_test_No_ohe = onehot_encoder.inverse_transform(y_test_ohe).ravel()\n",
    "\n",
    "# Création de 1000 random samples\n",
    "test_random = np.array([])\n",
    "y_random = np.array([])\n",
    "for i in range(1000):\n",
    "    r = random.randint(0, len(test))\n",
    "    test_random = np.insert(test_random, len(test_random), test[r])\n",
    "    y_random = np.insert(y_random, len(y_random), y_test_No_ohe[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0.0    8.0    108.0\n",
      "Actual                        \n",
      "0.0           60      0      0\n",
      "8.0            0    581      0\n",
      "108.0         21     26    312\n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "data = {'y_Actual':    y_random,\n",
    "        'y_Predicted': test_random}\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames = ['Actual'], colnames = ['Predicted'])\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
